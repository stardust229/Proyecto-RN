{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto STS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\usuario.DESKTOP-\n",
      "[nltk_data]     GDR7TES\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1257f3497d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(777) # seed para reproductibilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lectura de datos.** Dado que en este caso nuestros datos vienen en texto, necesitaremos realizar un \n",
    "proceso diferente para obtener los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df= pd.read_csv('train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Method to find separation of slits using fresnel biprism?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['question1'].iloc[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Separación de las preguntas en tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función es parte del preprocesamiento. Vamos a convertir cada oración en una lista de palabras, y vamos a homogenizar contracciones comunes de palabras en ingles (ya que las preguntas están en inglés)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "def text_to_word_list(text):\n",
    "    ''' Pre process and convert texts to a list of words '''\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que hacer lo siguiente: Para cada dataset, agregar las columnas `question1_vec` y `question2_vec`. Estas columnas contienen la respresentación de las preguntas como listas de embeddings, donde cada embedding (vector) corresponde a una de las palabras (tokens) de la pregunta.\n",
    "\n",
    "Para hacer esto, primero pasaremos cada pregunta por la función `text_to_word_list`, obteniendo la lista de tokens que le corresponden. En esta función se homogenizan algunas contracciones comunes.\n",
    "\n",
    "El resultado de pasar nuestar pregunta por `text_to_word_list` lo agregaremos al dataframe como una columna `question1_tokens` o `question2_tokens`.\n",
    "\n",
    "Luego, por cada lista de tokens, usaremos un modelo pre-entrenado de Word2Vec para asignarle un vector a cada palabra de la lista. Estas listas de vectores las guardaremos en las columnas `question1_vec` y `question2_vec`.\n",
    "\n",
    "Estas listas de vectores serán la entrada de nuestro modelo más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training dataset:\n",
    "train_question1_tokens = [text_to_word_list(q) for q in train_df['question1']]\n",
    "train_df['question1_tokens'] = train_question1_tokens\n",
    "\n",
    "train_question2_tokens = [text_to_word_list(q) for q in train_df['question2']]\n",
    "train_df['question2_tokens'] = train_question2_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora nuestro dataframe de entrenamiento tiene las columas extra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question1_tokens</th>\n",
       "      <th>question2</th>\n",
       "      <th>question2_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>[what, is, the, story, of, kohinoor, koh, -, i...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>[what, would, happen, if, the, indian, governm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>[how, can, i, increase, the, speed, of, my, in...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>[how, can, internet, speed, be, increased, by,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>[why, am, i, mentally, very, lonely, how, can,...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>[find, the, remainder, when, math, 23, ^, 24, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>[which, one, dissolve, in, water, quikly, suga...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>[which, fish, would, survive, in, salt, water]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                    question1_tokens  \\\n",
       "0  [what, is, the, step, by, step, guide, to, inv...   \n",
       "1  [what, is, the, story, of, kohinoor, koh, -, i...   \n",
       "2  [how, can, i, increase, the, speed, of, my, in...   \n",
       "3  [why, am, i, mentally, very, lonely, how, can,...   \n",
       "4  [which, one, dissolve, in, water, quikly, suga...   \n",
       "\n",
       "                                           question2  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What would happen if the Indian government sto...   \n",
       "2  How can Internet speed be increased by hacking...   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...   \n",
       "4            Which fish would survive in salt water?   \n",
       "\n",
       "                                    question2_tokens  \n",
       "0  [what, is, the, step, by, step, guide, to, inv...  \n",
       "1  [what, would, happen, if, the, indian, governm...  \n",
       "2  [how, can, internet, speed, be, increased, by,...  \n",
       "3  [find, the, remainder, when, math, 23, ^, 24, ...  \n",
       "4     [which, fish, would, survive, in, salt, water]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['question1', 'question1_tokens', 'question2', 'question2_tokens']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos solo las filas que **no** tengan más de 30 tokens en sus preguntas. Esto es sólo para que el entrenamiento no sea tan pesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300185"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función para checar si la longitud de question1_tokens y question2_tokens es menor o igual a 30\n",
    "def check_length(row):\n",
    "    if len(row['question1_tokens']) > 15 or len(row['question2_tokens']) > 15:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Aplicar la función check_length para filtrar el dataframe\n",
    "train_df = train_df[train_df.apply(lambda row: check_length(row), axis=1)]\n",
    "\n",
    "# Vemos cuántos ejemplares quedaron:\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do you think of mathematics as art or science?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['question1'].iloc[777]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Usamos menos ejemplares de los que hay disponibles porque mi computadora no es muy rápida\n",
    "train_df = train_df.head(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Agregar embeddings de Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tranformamos las listas de tokens a arreglos de numpy con su representación en vectores. Agregamos esas columnas al dataframe.\n",
    "\n",
    "Usaremos un modelo pre-entrenado de Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Cargamos el modelo pre-entrenado de word2vec\n",
    "model_file = \"w2v_model/google_news_word2vec.model\"\n",
    "word2vec = KeyedVectors.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_vector(token):\n",
    "    try:\n",
    "        return word2vec[token]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def tokens_to_vectors(token_list):\n",
    "    # si la palabra no existe en el vocabulario de word2vec, sólo la saltamos\n",
    "    vector_list = [vector for token in token_list if (vector := get_vector(token)) is not None]\n",
    "    if len(vector_list) > 0:\n",
    "        return vector_list\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training dataset:\n",
    "train_question1_vectors = [tokens_to_vectors(tk) for tk in train_df['question1_tokens']]\n",
    "train_df['question1_vectors'] = train_question1_vectors\n",
    "\n",
    "train_question2_vectors = [tokens_to_vectors(tk) for tk in train_df['question2_tokens']]\n",
    "train_df['question2_vectors'] = train_question2_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping rows with missing values: 300185\n",
      "After dropping rows with missing values: 300160\n"
     ]
    }
   ],
   "source": [
    "# Ahora eliminaremos las filas con algún valor None\n",
    "print('Before dropping rows with missing values:', len(train_df['question1_vectors']))\n",
    "train_df.dropna(inplace=True)\n",
    "print('After dropping rows with missing values:', len(train_df['question1_vectors']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question1_vectors</th>\n",
       "      <th>question2</th>\n",
       "      <th>question2_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>[[0.13964844, -0.006164551, 0.21484375, 0.0727...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>[[0.13964844, -0.006164551, 0.21484375, 0.0727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>[[0.26953125, 0.0859375, 0.09423828, 0.0410156...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>[[0.26953125, 0.0859375, 0.09423828, 0.0410156...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>[[0.15136719, 0.012451172, 0.21777344, 0.03039...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>[[-0.006958008, -0.043701172, -0.16796875, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>[[-0.06933594, 0.044677734, 0.091796875, 0.052...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>[[-0.06933594, 0.044677734, 0.091796875, 0.052...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Should I buy tiago?</td>\n",
       "      <td>[[-0.034423828, 0.041748047, 0.24902344, 0.228...</td>\n",
       "      <td>What keeps childern active and far from phone ...</td>\n",
       "      <td>[[0.13964844, -0.006164551, 0.21484375, 0.0727...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "6                                Should I buy tiago?   \n",
       "\n",
       "                                   question1_vectors  \\\n",
       "0  [[0.13964844, -0.006164551, 0.21484375, 0.0727...   \n",
       "2  [[0.26953125, 0.0859375, 0.09423828, 0.0410156...   \n",
       "3  [[0.15136719, 0.012451172, 0.21777344, 0.03039...   \n",
       "4  [[-0.06933594, 0.044677734, 0.091796875, 0.052...   \n",
       "6  [[-0.034423828, 0.041748047, 0.24902344, 0.228...   \n",
       "\n",
       "                                           question2  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "2  How can Internet speed be increased by hacking...   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...   \n",
       "4            Which fish would survive in salt water?   \n",
       "6  What keeps childern active and far from phone ...   \n",
       "\n",
       "                                   question2_vectors  \n",
       "0  [[0.13964844, -0.006164551, 0.21484375, 0.0727...  \n",
       "2  [[0.26953125, 0.0859375, 0.09423828, 0.0410156...  \n",
       "3  [[-0.006958008, -0.043701172, -0.16796875, 0.1...  \n",
       "4  [[-0.06933594, 0.044677734, 0.091796875, 0.052...  \n",
       "6  [[0.13964844, -0.006164551, 0.21484375, 0.0727...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['question1', 'question1_vectors', 'question2', 'question2_vectors']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>question1_tokens</th>\n",
       "      <th>question2_tokens</th>\n",
       "      <th>question1_vectors</th>\n",
       "      <th>question2_vectors</th>\n",
       "      <th>pair_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>[[0.13964844, -0.006164551, 0.21484375, 0.0727...</td>\n",
       "      <td>[[0.13964844, -0.006164551, 0.21484375, 0.0727...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>[how, can, i, increase, the, speed, of, my, in...</td>\n",
       "      <td>[how, can, internet, speed, be, increased, by,...</td>\n",
       "      <td>[[0.26953125, 0.0859375, 0.09423828, 0.0410156...</td>\n",
       "      <td>[[0.26953125, 0.0859375, 0.09423828, 0.0410156...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "      <td>[why, am, i, mentally, very, lonely, how, can,...</td>\n",
       "      <td>[find, the, remainder, when, math, 23, ^, 24, ...</td>\n",
       "      <td>[[0.15136719, 0.012451172, 0.21777344, 0.03039...</td>\n",
       "      <td>[[-0.006958008, -0.043701172, -0.16796875, 0.1...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "      <td>[which, one, dissolve, in, water, quikly, suga...</td>\n",
       "      <td>[which, fish, would, survive, in, salt, water]</td>\n",
       "      <td>[[-0.06933594, 0.044677734, 0.091796875, 0.052...</td>\n",
       "      <td>[[-0.06933594, 0.044677734, 0.091796875, 0.052...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Should I buy tiago?</td>\n",
       "      <td>What keeps childern active and far from phone ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[should, i, buy, tiago]</td>\n",
       "      <td>[what, keeps, childern, active, and, far, from...</td>\n",
       "      <td>[[-0.034423828, 0.041748047, 0.24902344, 0.228...</td>\n",
       "      <td>[[0.13964844, -0.006164551, 0.21484375, 0.0727...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "6   6    13    14                                Should I buy tiago?   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0  What is the step by step guide to invest in sh...             0   \n",
       "2  How can Internet speed be increased by hacking...             0   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0   \n",
       "4            Which fish would survive in salt water?             0   \n",
       "6  What keeps childern active and far from phone ...             0   \n",
       "\n",
       "                                    question1_tokens  \\\n",
       "0  [what, is, the, step, by, step, guide, to, inv...   \n",
       "2  [how, can, i, increase, the, speed, of, my, in...   \n",
       "3  [why, am, i, mentally, very, lonely, how, can,...   \n",
       "4  [which, one, dissolve, in, water, quikly, suga...   \n",
       "6                            [should, i, buy, tiago]   \n",
       "\n",
       "                                    question2_tokens  \\\n",
       "0  [what, is, the, step, by, step, guide, to, inv...   \n",
       "2  [how, can, internet, speed, be, increased, by,...   \n",
       "3  [find, the, remainder, when, math, 23, ^, 24, ...   \n",
       "4     [which, fish, would, survive, in, salt, water]   \n",
       "6  [what, keeps, childern, active, and, far, from...   \n",
       "\n",
       "                                   question1_vectors  \\\n",
       "0  [[0.13964844, -0.006164551, 0.21484375, 0.0727...   \n",
       "2  [[0.26953125, 0.0859375, 0.09423828, 0.0410156...   \n",
       "3  [[0.15136719, 0.012451172, 0.21777344, 0.03039...   \n",
       "4  [[-0.06933594, 0.044677734, 0.091796875, 0.052...   \n",
       "6  [[-0.034423828, 0.041748047, 0.24902344, 0.228...   \n",
       "\n",
       "                                   question2_vectors  pair_id  \n",
       "0  [[0.13964844, -0.006164551, 0.21484375, 0.0727...        0  \n",
       "2  [[0.26953125, 0.0859375, 0.09423828, 0.0410156...        2  \n",
       "3  [[-0.006958008, -0.043701172, -0.16796875, 0.1...        3  \n",
       "4  [[-0.06933594, 0.044677734, 0.091796875, 0.052...        4  \n",
       "6  [[0.13964844, -0.006164551, 0.21484375, 0.0727...        6  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a guardar por aquí la longitud máxima de la lista de tokens para ambas preguntas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_question1 = train_df['question1_tokens'].apply(lambda x: len(x)).max()\n",
    "max_length_question2 = train_df['question2_tokens'].apply(lambda x: len(x)).max()\n",
    "max_length_question = max_length_question1 if max_length_question1 >= max_length_question2 else max_length_question2\n",
    "max_length_question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Crear conjuntos de entrenamiento y prueba, y prepararlos para el dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define una función para transformar las columnas de los conjuntos a listas de tensores, para que puedan ser usados en el dataloader.\n",
    "\n",
    "También se define una función para agregarle padding a las secuencias, para que todas sean del mismo tamaño (los espacios extras se llenan con 0s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedded_vectors_to_tensors(question1_vectors, question2_vectors):\n",
    "    # Cambiamos los conjuntos a un diccionario y los transformamos en\n",
    "    # arreglos de numpy\n",
    "    X = {\n",
    "        'question1': [np.array(vecs) for vecs in question1_vectors],\n",
    "        'question2': [np.array(vecs) for vecs in question2_vectors]\n",
    "    }\n",
    "    # Ahora, transformamos las listas de las columnas de vectores en listas de tensores.\n",
    "    X = {\n",
    "        'question1': [torch.tensor(np_vecs) for np_vecs in X['question1']],\n",
    "        'question2': [torch.tensor(np_vecs) for np_vecs in X['question2']]\n",
    "    }\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Recibe una lista de (# de ejemplares) tensores de tamaño [max_sequence_length, word_vectors_length].\n",
    "Regresa un tensor de tamaño [# de ejemplares, max_sequence_length, word_vectors_length], con todos\n",
    "sus tensores de tamaño max_sequence_length con 0s en los espacios donde originalmente no había nada (padding).\n",
    "(Checa torch.nn.utils.rnn.pad_sequence)\n",
    "\"\"\"\n",
    "def tensorize_and_pad_sequences(sequences, max_sequence_length, word_vectors_length):\n",
    "    batch_size = 500  # Adjust the batch size as per your memory constraints\n",
    "    num_batches = (len(sequences) + batch_size - 1) // batch_size\n",
    "\n",
    "    dummy_tensor = torch.ones(max_sequence_length, word_vectors_length)\n",
    "\n",
    "    padded_sequences = []\n",
    "    for i in range(num_batches):\n",
    "        if i % 50 == 0:\n",
    "            print('batch: ',i)\n",
    "        batch = sequences[i * batch_size : (i + 1) * batch_size]\n",
    "        num_rows = len(batch)\n",
    "        batch.append(dummy_tensor)\n",
    "        padded_batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True)\n",
    "        padded_batch = torch.index_select(padded_batch, 0, torch.arange(num_rows))\n",
    "        padded_sequences.append(padded_batch)\n",
    "\n",
    "    return torch.cat(padded_sequences, dim=0)  # Concatenate the batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, se crea una función que recibe un dataframe, y regresa un diccionario X con un tensor para cada pregunta (question1 y question2) y uno para targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_length = 300\n",
    "\n",
    "def prepare_sample_df_for_dataloader(question1_vectors, question2_vectors, targets):    \n",
    "    X = embedded_vectors_to_tensors(question1_vectors, question2_vectors)\n",
    "    X['question1'] = tensorize_and_pad_sequences(X['question1'], max_length_question, word_vectors_length)\n",
    "    X['question2'] = tensorize_and_pad_sequences(X['question2'], max_length_question, word_vectors_length)\n",
    "    \n",
    "    targets = targets.values.tolist()\n",
    "    targets = torch.tensor(targets)\n",
    "    \n",
    "    print('size q1:', X['question1'].size()) # X.question1 tiene tamaño (NUM_EJEMPLARES, MAX_SENT_LEN, EMBEDDING_DIM).\n",
    "    print('size q2:', X['question2'].size())\n",
    "    print('size targets:', targets.size())\n",
    "    \n",
    "    return X, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separación de los conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[['id','question1_vectors', 'question2_vectors']]\n",
    "Y = train_df['is_duplicate']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creación del DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un DataSet y DataLoader para el conjunto de entrenamiento y de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QuestionsDataset(Dataset):\n",
    "    def __init__(self, ids, question1, question2, targets):\n",
    "        self.ids = ids\n",
    "        self.question1 = question1\n",
    "        self.question2 = question2\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        pairId = self.ids[index]\n",
    "        question1 = self.question1[index]\n",
    "        question2 = self.question2[index]\n",
    "        isDuplicate = self.targets[index]\n",
    "\n",
    "        return pairId, question1, question2, isDuplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  0\n",
      "batch:  50\n",
      "batch:  100\n",
      "batch:  150\n",
      "batch:  200\n",
      "batch:  250\n",
      "batch:  300\n",
      "batch:  350\n",
      "batch:  400\n",
      "batch:  450\n",
      "batch:  0\n",
      "batch:  50\n",
      "batch:  100\n",
      "batch:  150\n",
      "batch:  200\n",
      "batch:  250\n",
      "batch:  300\n",
      "batch:  350\n",
      "batch:  400\n",
      "batch:  450\n",
      "size q1: torch.Size([240128, 15, 300])\n",
      "size q2: torch.Size([240128, 15, 300])\n",
      "size targets: torch.Size([240128])\n"
     ]
    }
   ],
   "source": [
    "# El resultado de prepare_sample_df_for_dataloader lo podemos convertir a un QuestionsDataset para ingresarlo en el dataloader\n",
    "\n",
    "X, targets = prepare_sample_df_for_dataloader(X_train.question1_vectors, X_train.question2_vectors, Y_train)\n",
    "dataset_train = QuestionsDataset(X['question1'], X['question2'], targets)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 15, 300])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vemos que el tamaño sea correcto\n",
    "pairId, question1_batch, question2_batch, isDuplicate_batch = next(iter(dataloader_train))\n",
    "question1_batch.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Definición del modelo\n",
    "Una vez que se tienen las entradas, el modelo necesita 3 cosas: el codificador posicional, el encoder del transformador, y una función de similitud entre dos vectores (las salidas del encoder del transformador). Estas tres cosas las vamos a integrar en una red neuronal siamesa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Codificación posicional\n",
    "Se les aplica una codificación posicional a las secuencias de embeddings, para tomar en cuenta el orden de las secuencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "En el paper original por Vaswani et al., la matriz para codificar la posición se obtenía con las siguientes fórmulas:\n",
    "$$\n",
    "PE(\\text{position}, 2i) = \\sin\\bigg( \\frac{ \\text{position} }{10000^\\frac{2i}{d}} \\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "PE(\\text{position}, 2i+1) = \\cos\\bigg( \\frac{ \\text{position} }{10000^\\frac{2i}{d}} \\bigg)\n",
    "$$\n",
    "\n",
    "donde *d* es la dimensión de los vectores de los tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer la codificación posicional se crea una clase PositionalEncoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Create the positional encoding matrix\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add the positional encoding to the input\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 15, 300])\n"
     ]
    }
   ],
   "source": [
    "positionalEncoder = PositionalEncoding(word_vectors_length, max_seq_len = max_length_question)\n",
    "question1_batch = positionalEncoder(question1_batch)\n",
    "print(question1_batch.shape)              # (BATCH_SIZE, SEQ_LEN, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### El encoder del transformador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 15, 300])\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = word_vectors_length\n",
    "HIDDEN_SIZE = 16\n",
    "NUM_HEADS = 5\n",
    "DROPOUT = .3\n",
    "\n",
    "enc_layer = nn.TransformerEncoderLayer(EMBEDDING_DIM, NUM_HEADS, HIDDEN_SIZE, DROPOUT, batch_first=True)\n",
    "encoder_result = enc_layer(question1_batch)\n",
    "print(encoder_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pooling\n",
    "En el paper de SBERT usan mean pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_encoder_result = encoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "poolingLayer = nn.AvgPool2d(kernel_size=(1, word_vectors_length), stride=(1, word_vectors_length))\n",
    "output = poolingLayer(one_encoder_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 15, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### La función de similitud\n",
    "En el paper de SBERT usan cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Construcción de la red siamesa\n",
    "La red va a tener un encoder de transformador en cada lado, y los vectores resultantes se van a comparar con cosine_similarity ???\n",
    "\n",
    "// Mostrar una imagen de la arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    EMBEDDING_DIM = word_vectors_length\n",
    "    HIDDEN_SIZE = 32\n",
    "    NUM_HEADS = 5\n",
    "    DROPOUT = .1\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        # Positional Encodder\n",
    "        self.positionalEncoder = PositionalEncoding(word_vectors_length, max_seq_len = max_length_question)\n",
    "\n",
    "        # Capas de encoders de transformadores\n",
    "        self.transformer_encoder_1 = nn.TransformerEncoderLayer(EMBEDDING_DIM, NUM_HEADS, HIDDEN_SIZE, DROPOUT, batch_first=True)\n",
    "        self.transformer_encoder_2 = nn.TransformerEncoderLayer(EMBEDDING_DIM, NUM_HEADS, HIDDEN_SIZE, DROPOUT, batch_first=True)\n",
    "        self.transformer_encoder_3 = nn.TransformerEncoderLayer(EMBEDDING_DIM, NUM_HEADS, HIDDEN_SIZE, DROPOUT, batch_first=True)\n",
    "        self.transformer_encoder_4 = nn.TransformerEncoderLayer(EMBEDDING_DIM, NUM_HEADS, HIDDEN_SIZE, DROPOUT, batch_first=True)\n",
    "        \n",
    "\n",
    "        # Mean Pooling\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=(1, word_vectors_length), stride=(1, word_vectors_length))\n",
    "\n",
    "        # Cosine Similarity\n",
    "        self.cos_similarity = nn.CosineSimilarity(dim=1)\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # Pasamos la pregunta 1:\n",
    "        input1 = self.positionalEncoder(input1)\n",
    "        output1 = self.transformer_encoder_1(input1)\n",
    "        output1 = self.transformer_encoder_2(input1)\n",
    "        output1 = self.transformer_encoder_3(input1)\n",
    "        output1 = self.transformer_encoder_4(input1)\n",
    "        output1 = self.avg_pool(output1)\n",
    "        output1 = torch.flatten(output1, start_dim=1)\n",
    "        \n",
    "        # Pasamos la pregunta 2:\n",
    "        input2 = self.positionalEncoder(input2)\n",
    "        output2 = self.transformer_encoder_1(input2)\n",
    "        output2 = self.transformer_encoder_2(input2)\n",
    "        output2 = self.transformer_encoder_3(input2)\n",
    "        output2 = self.transformer_encoder_4(input2)\n",
    "        output2 = self.avg_pool(output2)\n",
    "        output2 = torch.flatten(output2, start_dim=1)\n",
    "\n",
    "        # Compute Cosine Similarity\n",
    "        similarity = self.cos_similarity(output1, output2)\n",
    "\n",
    "        return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "En el paper de SBERT usan  batch-size of 16, Adam optimizer with\n",
    "learning rate 2e−5, and a linear learning rate\n",
    "warm-up over 10% of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_accuracy_one_batch(dataloader):\n",
    "    pairId_batch, question1_batch, question2_batch, isDuplicate_batch = next(iter(dataloader))\n",
    "    predicted_similarity = modelo(question1_batch, question2_batch)\n",
    "    predicted_similarity = predicted_similarity.detach()\n",
    "    predicted_similarity = torch.where(predicted_similarity > 0.65, 1, 0)\n",
    "    return accuracy_score(isDuplicate_batch, predicted_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  0\n",
      "batch:  50\n",
      "batch:  100\n",
      "batch:  0\n",
      "batch:  50\n",
      "batch:  100\n",
      "size q1: torch.Size([60032, 15, 300])\n",
      "size q2: torch.Size([60032, 15, 300])\n",
      "size targets: torch.Size([60032])\n"
     ]
    }
   ],
   "source": [
    "# Para ir mostrando la accuracy en el conjunto de prueba\n",
    "X, targets = prepare_sample_df_for_dataloader(X_test.question1_vectors, X_test.question2_vectors, Y_test)\n",
    "dataset_test = QuestionsDataset(X['question1'], X['question2'], targets)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=512, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the MSE loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "learning_rate = 0.0001\n",
    "\n",
    "def train(dataloader, model, epochs, dataloader_test):\n",
    "    print(\"::: Iniciando entrenamiento... :::\")\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    all_losses = []\n",
    "    all_accuracies = []\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        batch_num = 0\n",
    "        print(\"-------------------------------------------------------------------------------------\")\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        for data in dataloader:\n",
    "            pairId, input1, input2, target_similarity = data\n",
    "            optimizer.zero_grad()\n",
    "            output_similarity = model(input1, input2)\n",
    "            # Convertir target_similarity al mismo tipo de dato que output_similarity\n",
    "            target_similarity = target_similarity.to(output_similarity.dtype)\n",
    "            loss = criterion(output_similarity, target_similarity)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_num % 100 == 0:\n",
    "                all_losses.append(loss.item())\n",
    "                \n",
    "            if batch_num % 300 == 0:\n",
    "                print(f\"Epoch: {epoch},  Batch number: {batch_num},  Loss: {loss.item()}\")\n",
    "            batch_num = batch_num + 1\n",
    "        \n",
    "        print(\"-------------------------------------------------------------------------------------\")\n",
    "        accuracy = get_accuracy_one_batch(dataloader_test)\n",
    "        print(f\"Accuracy in test batch: {accuracy}\")\n",
    "        all_accuracies.append(accuracy)\n",
    "        \n",
    "    print(\"::: ...Fin del entrenamiento :::\")\n",
    "    return all_losses, all_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear un modelo llamado *modelo* (por quora question pairs). Y vamos a ir entrenando por separado cada epoch. Después de entrenar un epoc vamos a ir guardando el modelo en la dirección especificada. Esto para no perder el progreso del entrenamiento si se  acaba la memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo\n",
    "modelo = SiameseNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: Iniciando entrenamiento... :::\n",
      "-------------------------------------------------------------------------------------\n",
      "Epoch: 0\n",
      "Epoch: 0,  Batch number: 0,  Loss: 0.6447086930274963\n",
      "Epoch: 0,  Batch number: 300,  Loss: 0.2891513407230377\n",
      "Epoch: 0,  Batch number: 600,  Loss: 0.2763463258743286\n",
      "Epoch: 0,  Batch number: 900,  Loss: 0.223073810338974\n",
      "Epoch: 0,  Batch number: 1200,  Loss: 0.22852036356925964\n",
      "Epoch: 0,  Batch number: 1500,  Loss: 0.2583838999271393\n",
      "Epoch: 0,  Batch number: 1800,  Loss: 0.18314984440803528\n",
      "Epoch: 0,  Batch number: 2100,  Loss: 0.2643792927265167\n",
      "Epoch: 0,  Batch number: 2400,  Loss: 0.23254840075969696\n",
      "Epoch: 0,  Batch number: 2700,  Loss: 0.22965632379055023\n",
      "Epoch: 0,  Batch number: 3000,  Loss: 0.3025355935096741\n",
      "Epoch: 0,  Batch number: 3300,  Loss: 0.2611190676689148\n",
      "Epoch: 0,  Batch number: 3600,  Loss: 0.208376944065094\n",
      "-------------------------------------------------------------------------------------\n",
      "Accuracy in test batch: 0.57421875\n",
      "::: ...Fin del entrenamiento :::\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos 20 epochs\n",
    "losses, accuracies = train(dataloader_train, modelo, 20, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos\n",
    "torch.save(modelo.state_dict(), \"modelo_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pairId_batch, question1_batch, question2_batch, isDuplicate_batch = next(iter(dataloader_test))\n",
    "#predicted_similarity = modelo(question1_batch, question2_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.615234375"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted_similarity = predicted_similarity.detach()\n",
    "#predicted_similarity2 = torch.where(predicted_similarity > 0.65, 1, 0)\n",
    "#accuracy_score(isDuplicate_batch, predicted_similarity2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# accumulated_losses = accumulated_losses + losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"Batch (x50)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Configuración 1 con 80k: Pérdida a lo largo de 20 epochs de entrenamiento\")\n",
    "plt.savefig('plot_config1_80k_20eps.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(accuracies)\n",
    "plt.xlabel(\"Batch (x50)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Configuración 2: Accuracy a lo largo de 10 epochs de entrenamiento\")\n",
    "plt.savefig('plot_config2.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados con diferentes configuraciones:\n",
    "\n",
    "### Configuración 1 con 80k ejemplares:\n",
    "    - aprox. 80k ejemplares para entrenamiento\n",
    "    - adam optimizer\n",
    "    - learning rate: 0.0001\n",
    "    - batch size: 64\n",
    "    - 4 capas de encoders (en cada lado de la red):\n",
    "        - 5 cabezas de atención\n",
    "        - hidden size = 32 en la capa feed forward\n",
    "        - dropout 0.1\n",
    "\n",
    "La red neuronal da como resultado, para cada ejemplar, un número entre 0 y 1, representando la similitud entre las dos preguntas. Entre más grande sea este número más similares son.\n",
    "Para obtener resultados binarios convertimos en 1 todos los resultados mayores a **0.65**, y el resto en 0.\n",
    "Después del entrenamiento, con la configuración 1, y esta forma de interpretar el resultado, se obtiene los siguientes valores de accuracy para 4 batches random de tamaño **1024** del conjunto de prueba:\n",
    "- Accuracy batch 1:    0.6728515625\n",
    "- Accuracy batch 2:    0.65625\n",
    "- Accuracy batch 3:    0.662109375\n",
    "- Accuracy batch 4:    0.6611328125\n",
    "\n",
    "### Configuración 2 con 240k ejemplares:\n",
    "    - aprox. 240k ejemplares para entrenamiento\n",
    "    - adam optimizer\n",
    "    - learning rate: 0.00005\n",
    "    - batch size: 64\n",
    "    - 6 capas de encoders (en cada lado de la red):\n",
    "        - 6 cabezas de atención\n",
    "        - hidden size = 384 en la capa feed forward\n",
    "        - dropout 0.1\n",
    "\n",
    "Después de **un epoch** (porque en esta configuración cada epoch tardaba lo mismo que 10 epochs en la configuración 1) se obtiene los siguientes valores de accuracy para 4 batches random de tamaño **512** del conjunto de prueba:\n",
    "- Accuracy batch 1:    0.6171875\n",
    "- Accuracy batch 2:    0.6015625\n",
    "- Accuracy batch 3:    0.611328125\n",
    "- Accuracy batch 4:    0.6015625\n",
    "\n",
    "Después de **dos epoch**:\n",
    "- Accuracy batch 1:    0.576171875\n",
    "- Accuracy batch 2:    0.61328125\n",
    "- Accuracy batch 3:    0.634765625\n",
    "- Accuracy batch 4:    0.62109375\n",
    "\n",
    "### Configuración 1 con 240k ejemplares:\n",
    "    - aprox. 240k ejemplares para entrenamiento\n",
    "    - adam optimizer\n",
    "    - learning rate: 0.0001\n",
    "    - batch size: 64\n",
    "    - 4 capas de encoders (en cada lado de la red):\n",
    "        - 5 cabezas de atención\n",
    "        - hidden size = 32 en la capa feed forward\n",
    "        - dropout 0.1\n",
    "\n",
    "Después de **un epoch** (porque en esta configuración cada epoch tardaba lo mismo que 10 epochs en la configuración 1) se obtiene los siguientes valores de accuracy para 4 batches random de tamaño **512** del conjunto de prueba:\n",
    "- Accuracy batch 1:    0.59765625\n",
    "- Accuracy batch 2:    0.609375\n",
    "- Accuracy batch 3:    0.62890625\n",
    "- Accuracy batch 4:    0.615234375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Define the MSE loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "all_losses = []\n",
    "losses_per_epoch = []\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: min(1.0, (epoch + 1) / (0.1 * num_epochs)))\n",
    "\n",
    "print(\"Iniciando el entrenamiento...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss = 0\n",
    "    print(\"~ Epoch:\", epoch+1)\n",
    "    batch_num = 0\n",
    "    for data in train_dataloader:\n",
    "        \n",
    "        input1, input2, target_similarity = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_similarity = model(input1, input2)\n",
    "        \n",
    "        # Convertir target_similarity al mismo tipo de dato que output_similarity\n",
    "        target_similarity = target_similarity.to(output_similarity.dtype)\n",
    "\n",
    "        loss = criterion(output_similarity, target_similarity)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        if batch_num % 300 == 0:\n",
    "            print(f\"Batch number:: {batch_num}\")\n",
    "            all_losses.append(loss.item())\n",
    "        batch_num = batch_num + 1\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}, Learning Rate: {scheduler.get_last_lr()[0]}\")\n",
    "    losses_per_epoch.append(loss.item())\n",
    "print(\"¡Fin del entrenamiento!\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
