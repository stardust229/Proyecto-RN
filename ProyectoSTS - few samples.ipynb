{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto STS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\usuario.DESKTOP-\n",
      "[nltk_data]     GDR7TES\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x16e6b4e4b30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(777) # seed para reproductibilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lectura de datos.** Dado que en este caso nuestros datos vienen en texto, necesitaremos realizar un \n",
    "proceso diferente para obtener los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df= pd.read_csv('train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Method to find separation of slits using fresnel biprism?'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['question1'].iloc[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Separación de las preguntas en tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función es parte del preprocesamiento. Vamos a convertir cada oración en una lista de palabras, y vamos a homogenizar contracciones comunes de palabras en ingles (ya que las preguntas están en inglés)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "def text_to_word_list(text):\n",
    "    ''' Pre process and convert texts to a list of words '''\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que hacer lo siguiente: Para cada dataset, agregar las columnas `question1_vec` y `question2_vec`. Estas columnas contienen la respresentación de las preguntas como listas de embeddings, donde cada embedding (vector) corresponde a una de las palabras (tokens) de la pregunta.\n",
    "\n",
    "Para hacer esto, primero pasaremos cada pregunta por la función `text_to_word_list`, obteniendo la lista de tokens que le corresponden. En esta función se homogenizan algunas contracciones comunes.\n",
    "\n",
    "El resultado de pasar nuestar pregunta por `text_to_word_list` lo agregaremos al dataframe como una columna `question1_tokens` o `question2_tokens`.\n",
    "\n",
    "Luego, por cada lista de tokens, usaremos un modelo pre-entrenado de Word2Vec para asignarle un vector a cada palabra de la lista. Estas listas de vectores las guardaremos en las columnas `question1_vec` y `question2_vec`.\n",
    "\n",
    "Estas listas de vectores serán la entrada de nuestro modelo más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training dataset:\n",
    "train_question1_tokens = [text_to_word_list(q) for q in train_df['question1']]\n",
    "train_df['question1_tokens'] = train_question1_tokens\n",
    "\n",
    "train_question2_tokens = [text_to_word_list(q) for q in train_df['question2']]\n",
    "train_df['question2_tokens'] = train_question2_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora nuestro dataframe de entrenamiento tiene las columas extra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question1_tokens</th>\n",
       "      <th>question2</th>\n",
       "      <th>question2_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>[what, is, the, story, of, kohinoor, koh, -, i...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>[what, would, happen, if, the, indian, governm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>[how, can, i, increase, the, speed, of, my, in...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>[how, can, internet, speed, be, increased, by,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>[why, am, i, mentally, very, lonely, how, can,...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>[find, the, remainder, when, math, 23, ^, 24, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>[which, one, dissolve, in, water, quikly, suga...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>[which, fish, would, survive, in, salt, water]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                    question1_tokens  \\\n",
       "0  [what, is, the, step, by, step, guide, to, inv...   \n",
       "1  [what, is, the, story, of, kohinoor, koh, -, i...   \n",
       "2  [how, can, i, increase, the, speed, of, my, in...   \n",
       "3  [why, am, i, mentally, very, lonely, how, can,...   \n",
       "4  [which, one, dissolve, in, water, quikly, suga...   \n",
       "\n",
       "                                           question2  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What would happen if the Indian government sto...   \n",
       "2  How can Internet speed be increased by hacking...   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...   \n",
       "4            Which fish would survive in salt water?   \n",
       "\n",
       "                                    question2_tokens  \n",
       "0  [what, is, the, step, by, step, guide, to, inv...  \n",
       "1  [what, would, happen, if, the, indian, governm...  \n",
       "2  [how, can, internet, speed, be, increased, by,...  \n",
       "3  [find, the, remainder, when, math, 23, ^, 24, ...  \n",
       "4     [which, fish, would, survive, in, salt, water]  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['question1', 'question1_tokens', 'question2', 'question2_tokens']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos solo las filas que **no** tengan más de 30 tokens en sus preguntas. Esto es sólo para que el entrenamiento no sea tan pesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300185"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Función para checar si la longitud de question1_tokens y question2_tokens es menor o igual a 30\n",
    "def check_length(row):\n",
    "    if len(row['question1_tokens']) > 15 or len(row['question2_tokens']) > 15:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Aplicar la función check_length para filtrar el dataframe\n",
    "train_df = train_df[train_df.apply(lambda row: check_length(row), axis=1)]\n",
    "\n",
    "# Vemos cuántos ejemplares quedaron:\n",
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Do you think of mathematics as art or science?'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['question1'].iloc[777]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Usamos menos ejemplares de los que hay disponibles porque mi computadora no tiene mucha memoria\n",
    "train_df = train_df.sample(n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Agregar embeddings de Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tranformamos las listas de tokens a arreglos de numpy con su representación en vectores. Agregamos esas columnas al dataframe.\n",
    "\n",
    "Usaremos un modelo pre-entrenado de Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Cargamos el modelo pre-entrenado de word2vec\n",
    "model_file = \"w2v_model/google_news_word2vec.model\"\n",
    "word2vec = KeyedVectors.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_vector(token):\n",
    "    try:\n",
    "        return word2vec[token]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def tokens_to_vectors(token_list):\n",
    "    # si la palabra no existe en el vocabulario de word2vec, sólo la saltamos\n",
    "    vector_list = [vector for token in token_list if (vector := get_vector(token)) is not None]\n",
    "    if len(vector_list) > 0:\n",
    "        return vector_list\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training dataset:\n",
    "train_question1_vectors = [tokens_to_vectors(tk) for tk in train_df['question1_tokens']]\n",
    "train_df['question1_vectors'] = train_question1_vectors\n",
    "\n",
    "train_question2_vectors = [tokens_to_vectors(tk) for tk in train_df['question2_tokens']]\n",
    "train_df['question2_vectors'] = train_question2_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping rows with missing values: 90000\n",
      "After dropping rows with missing values: 89992\n"
     ]
    }
   ],
   "source": [
    "# Ahora eliminaremos las filas con algún valor None\n",
    "print('Before dropping rows with missing values:', len(train_df['question1_vectors']))\n",
    "train_df.dropna(inplace=True)\n",
    "print('After dropping rows with missing values:', len(train_df['question1_vectors']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question1_vectors</th>\n",
       "      <th>question2</th>\n",
       "      <th>question2_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158843</th>\n",
       "      <td>How do I delete a question from Quora?</td>\n",
       "      <td>[[0.26953125, 0.0859375, 0.09423828, 0.0410156...</td>\n",
       "      <td>How can you delete a question that you asked o...</td>\n",
       "      <td>[[0.26953125, 0.0859375, 0.09423828, 0.0410156...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118337</th>\n",
       "      <td>Why is phenol more acidic than ethanol?</td>\n",
       "      <td>[[0.15136719, 0.012451172, 0.21777344, 0.03039...</td>\n",
       "      <td>Why is hydroquinone more acidic than phenol?</td>\n",
       "      <td>[[0.15136719, 0.012451172, 0.21777344, 0.03039...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81829</th>\n",
       "      <td>What are the best comments that we share on a ...</td>\n",
       "      <td>[[0.13964844, -0.006164551, 0.21484375, 0.0727...</td>\n",
       "      <td>How can I steal a girl's heart and impress her?</td>\n",
       "      <td>[[0.26953125, 0.0859375, 0.09423828, 0.0410156...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218195</th>\n",
       "      <td>What should I do in free time?</td>\n",
       "      <td>[[0.13964844, -0.006164551, 0.21484375, 0.0727...</td>\n",
       "      <td>What do you do when you got free time?</td>\n",
       "      <td>[[0.13964844, -0.006164551, 0.21484375, 0.0727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70427</th>\n",
       "      <td>What are some of the best science fiction nove...</td>\n",
       "      <td>[[0.13964844, -0.006164551, 0.21484375, 0.0727...</td>\n",
       "      <td>What are the best science fiction novels?</td>\n",
       "      <td>[[0.13964844, -0.006164551, 0.21484375, 0.0727...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                question1  \\\n",
       "158843             How do I delete a question from Quora?   \n",
       "118337            Why is phenol more acidic than ethanol?   \n",
       "81829   What are the best comments that we share on a ...   \n",
       "218195                     What should I do in free time?   \n",
       "70427   What are some of the best science fiction nove...   \n",
       "\n",
       "                                        question1_vectors  \\\n",
       "158843  [[0.26953125, 0.0859375, 0.09423828, 0.0410156...   \n",
       "118337  [[0.15136719, 0.012451172, 0.21777344, 0.03039...   \n",
       "81829   [[0.13964844, -0.006164551, 0.21484375, 0.0727...   \n",
       "218195  [[0.13964844, -0.006164551, 0.21484375, 0.0727...   \n",
       "70427   [[0.13964844, -0.006164551, 0.21484375, 0.0727...   \n",
       "\n",
       "                                                question2  \\\n",
       "158843  How can you delete a question that you asked o...   \n",
       "118337       Why is hydroquinone more acidic than phenol?   \n",
       "81829     How can I steal a girl's heart and impress her?   \n",
       "218195             What do you do when you got free time?   \n",
       "70427           What are the best science fiction novels?   \n",
       "\n",
       "                                        question2_vectors  \n",
       "158843  [[0.26953125, 0.0859375, 0.09423828, 0.0410156...  \n",
       "118337  [[0.15136719, 0.012451172, 0.21777344, 0.03039...  \n",
       "81829   [[0.26953125, 0.0859375, 0.09423828, 0.0410156...  \n",
       "218195  [[0.13964844, -0.006164551, 0.21484375, 0.0727...  \n",
       "70427   [[0.13964844, -0.006164551, 0.21484375, 0.0727...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['question1', 'question1_vectors', 'question2', 'question2_vectors']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a guardar por aquí la longitud máxima de la lista de tokens para ambas preguntas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_question1 = train_df['question1_tokens'].apply(lambda x: len(x)).max()\n",
    "max_length_question2 = train_df['question2_tokens'].apply(lambda x: len(x)).max()\n",
    "max_length_question = max_length_question1 if max_length_question1 >= max_length_question2 else max_length_question2\n",
    "max_length_question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Crear conjuntos de entrenamiento y prueba, y prepararlos para el dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define una función para transformar las columnas de los conjuntos a listas de tensores, para que puedan ser usados en el dataloader.\n",
    "\n",
    "También se define una función para agregarle padding a las secuencias, para que todas sean del mismo tamaño (los espacios extras se llenan con 0s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedded_vectors_to_tensors(question1_vectors, question2_vectors):\n",
    "    # Cambiamos los conjuntos a un diccionario y los transformamos en\n",
    "    # arreglos de numpy\n",
    "    X = {\n",
    "        'question1': [np.array(vecs) for vecs in question1_vectors],\n",
    "        'question2': [np.array(vecs) for vecs in question2_vectors]\n",
    "    }\n",
    "    # Ahora, transformamos las listas de las columnas de vectores en listas de tensores.\n",
    "    X = {\n",
    "        'question1': [torch.tensor(np_vecs) for np_vecs in X['question1']],\n",
    "        'question2': [torch.tensor(np_vecs) for np_vecs in X['question2']]\n",
    "    }\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Recibe una lista de (# de ejemplares) tensores de tamaño [max_sequence_length, word_vectors_length].\n",
    "Regresa un tensor de tamaño [# de ejemplares, max_sequence_length, word_vectors_length], con todos\n",
    "sus tensores de tamaño max_sequence_length con 0s en los espacios donde originalmente no había nada (padding).\n",
    "(Checa torch.nn.utils.rnn.pad_sequence)\n",
    "\"\"\"\n",
    "def tensorize_and_pad_sequences(sequences, max_sequence_length, word_vectors_length):\n",
    "    batch_size = 500  # Adjust the batch size as per your memory constraints\n",
    "    num_batches = (len(sequences) + batch_size - 1) // batch_size\n",
    "\n",
    "    dummy_tensor = torch.ones(max_sequence_length, word_vectors_length)\n",
    "\n",
    "    padded_sequences = []\n",
    "    for i in range(num_batches):\n",
    "        if i % 10 == 0:\n",
    "            print('batch: ',i)\n",
    "        batch = sequences[i * batch_size : (i + 1) * batch_size]\n",
    "        num_rows = len(batch)\n",
    "        batch.append(dummy_tensor)\n",
    "        padded_batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True)\n",
    "        padded_batch = torch.index_select(padded_batch, 0, torch.arange(num_rows))\n",
    "        padded_sequences.append(padded_batch)\n",
    "\n",
    "    return torch.cat(padded_sequences, dim=0)  # Concatenate the batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, se crea una función que recibe un dataframe, y regresa un diccionario X con un tensor para cada pregunta (question1 y question2) y uno para targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_length = 300\n",
    "\n",
    "def prepare_sample_df_for_dataloader(question1_vectors, question2_vectors, targets):    \n",
    "    X = embedded_vectors_to_tensors(question1_vectors, question2_vectors)\n",
    "    X['question1'] = tensorize_and_pad_sequences(X['question1'], max_length_question, word_vectors_length)\n",
    "    X['question2'] = tensorize_and_pad_sequences(X['question2'], max_length_question, word_vectors_length)\n",
    "    \n",
    "    targets = targets.values.tolist()\n",
    "    targets = torch.tensor(targets)\n",
    "    \n",
    "    print('size q1:', X['question1'].size()) # X.question1 tiene tamaño (NUM_EJEMPLARES, MAX_SENT_LEN, EMBEDDING_DIM).\n",
    "    print('size q2:', X['question2'].size())\n",
    "    print('size targets:', targets.size())\n",
    "    \n",
    "    return X, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separación de los conjuntos de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[['question1_vectors', 'question2_vectors']]\n",
    "Y = train_df['is_duplicate']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creación del DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un DataSet y DataLoader para el conjunto de entrenamiento y de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QuestionsDataset(Dataset):\n",
    "    def __init__(self, question1, question2, targets):\n",
    "        self.question1 = question1\n",
    "        self.question2 = question2\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        question1 = self.question1[index]\n",
    "        question2 = self.question2[index]\n",
    "        isDuplicate = self.targets[index]\n",
    "\n",
    "        return question1, question2, isDuplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  0\n",
      "batch:  10\n",
      "batch:  20\n",
      "batch:  30\n",
      "batch:  40\n",
      "batch:  50\n",
      "batch:  60\n",
      "batch:  70\n",
      "batch:  80\n",
      "batch:  90\n",
      "batch:  100\n",
      "batch:  110\n",
      "batch:  120\n",
      "batch:  0\n",
      "batch:  10\n",
      "batch:  20\n",
      "batch:  30\n",
      "batch:  40\n",
      "batch:  50\n",
      "batch:  60\n",
      "batch:  70\n",
      "batch:  80\n",
      "batch:  90\n",
      "batch:  100\n",
      "batch:  110\n",
      "batch:  120\n",
      "size q1: torch.Size([60294, 15, 300])\n",
      "size q2: torch.Size([60294, 15, 300])\n",
      "size targets: torch.Size([60294])\n"
     ]
    }
   ],
   "source": [
    "# El resultado de prepare_sample_df_for_dataloader lo podemos convertir a un QuestionsDataset para ingresarlo en el dataloader\n",
    "\n",
    "X, targets = prepare_sample_df_for_dataloader(X_train.question1_vectors, X_train.question2_vectors, Y_train)\n",
    "dataset_train = QuestionsDataset(X['question1'], X['question2'], targets)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 15, 300])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vemos que el tamaño sea correcto\n",
    "question1_batch, question2_batch, isDuplicate_batch = next(iter(dataloader_train))\n",
    "question1_batch.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Definición del modelo\n",
    "Una vez que se tienen las entradas, el modelo necesita 3 cosas: el codificador posicional, el encoder del transformador, y una función de similitud entre dos vectores (las salidas del encoder del transformador). Estas tres cosas las vamos a integrar en una red neuronal siamesa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Codificación posicional\n",
    "Se les aplica una codificación posicional a las secuencias de embeddings, para tomar en cuenta el orden de las secuencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "En el paper original por Vaswani et al., la matriz para codificar la posición se obtenía con las siguientes fórmulas:\n",
    "$$\n",
    "PE(\\text{position}, 2i) = \\sin\\bigg( \\frac{ \\text{position} }{10000^\\frac{2i}{d}} \\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "PE(\\text{position}, 2i+1) = \\cos\\bigg( \\frac{ \\text{position} }{10000^\\frac{2i}{d}} \\bigg)\n",
    "$$\n",
    "\n",
    "donde *d* es la dimensión de los vectores de los tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer la codificación posicional se crea una clase PositionalEncoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Create the positional encoding matrix\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add the positional encoding to the input\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 15, 300])\n"
     ]
    }
   ],
   "source": [
    "positionalEncoder = PositionalEncoding(word_vectors_length, max_seq_len = max_length_question)\n",
    "question1_batch = positionalEncoder(question1_batch)\n",
    "print(question1_batch.shape)              # (BATCH_SIZE, SEQ_LEN, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### El encoder del transformador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 15, 300])\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = word_vectors_length\n",
    "HIDDEN_SIZE = 16\n",
    "NUM_HEADS = 5\n",
    "DROPOUT = .3\n",
    "\n",
    "enc_layer = nn.TransformerEncoderLayer(EMBEDDING_DIM, NUM_HEADS, HIDDEN_SIZE, DROPOUT, batch_first=True)\n",
    "encoder_result = enc_layer(question1_batch)\n",
    "print(encoder_result.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pooling\n",
    "En el paper de SBERT usan mean pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_encoder_result = encoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "poolingLayer = nn.AvgPool2d(kernel_size=(1, word_vectors_length), stride=(1, word_vectors_length))\n",
    "output = poolingLayer(one_encoder_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 15, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### La función de similitud\n",
    "En el paper de SBERT usan cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Construcción de la red siamesa\n",
    "La red va a tener un encoder de transformador en cada lado, y los vectores resultantes se van a comparar con cosine_similarity ???\n",
    "\n",
    "// Mostrar una imagen de la arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = word_vectors_length\n",
    "HIDDEN_SIZE = 32\n",
    "NUM_HEADS = 5\n",
    "DROPOUT = .1\n",
    "\n",
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        # Positional Encodder\n",
    "        self.positionalEncoder = PositionalEncoding(word_vectors_length, max_seq_len = max_length_question)\n",
    "\n",
    "        # Capas de encoders de transformadores\n",
    "        self.transformer_encoder_1 = nn.TransformerEncoderLayer(EMBEDDING_DIM, NUM_HEADS, HIDDEN_SIZE, DROPOUT, batch_first=True)\n",
    "        self.transformer_encoder_2 = nn.TransformerEncoderLayer(EMBEDDING_DIM, NUM_HEADS, HIDDEN_SIZE, DROPOUT, batch_first=True)\n",
    "        self.transformer_encoder_3 = nn.TransformerEncoderLayer(EMBEDDING_DIM, NUM_HEADS, HIDDEN_SIZE, DROPOUT, batch_first=True)\n",
    "        self.transformer_encoder_4 = nn.TransformerEncoderLayer(EMBEDDING_DIM, NUM_HEADS, HIDDEN_SIZE, DROPOUT, batch_first=True)\n",
    "        \n",
    "\n",
    "        # Mean Pooling\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=(1, word_vectors_length), stride=(1, word_vectors_length))\n",
    "\n",
    "        # Cosine Similarity\n",
    "        self.cos_similarity = nn.CosineSimilarity(dim=1)\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # Pasamos la pregunta 1:\n",
    "        input1 = self.positionalEncoder(input1)\n",
    "        output1 = self.transformer_encoder_1(input1)\n",
    "        output1 = self.transformer_encoder_2(input1)\n",
    "        output1 = self.transformer_encoder_3(input1)\n",
    "        output1 = self.transformer_encoder_4(input1)\n",
    "        output1 = self.avg_pool(output1)\n",
    "        output1 = torch.flatten(output1, start_dim=1)\n",
    "        \n",
    "        # Pasamos la pregunta 2:\n",
    "        input2 = self.positionalEncoder(input2)\n",
    "        output2 = self.transformer_encoder_1(input2)\n",
    "        output2 = self.transformer_encoder_2(input2)\n",
    "        output2 = self.transformer_encoder_3(input2)\n",
    "        output2 = self.transformer_encoder_4(input2)\n",
    "        output2 = self.avg_pool(output2)\n",
    "        output2 = torch.flatten(output2, start_dim=1)\n",
    "\n",
    "        # Compute Cosine Similarity\n",
    "        similarity = self.cos_similarity(output1, output2)\n",
    "\n",
    "        return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "En el paper de SBERT usan  batch-size of 16, Adam optimizer with\n",
    "learning rate 2e−5, and a linear learning rate\n",
    "warm-up over 10% of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the MSE loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "learning_rate = 0.0001\n",
    "\n",
    "def train(dataloader, model, epochs):\n",
    "    print(\"::: Iniciando entrenamiento... :::\")\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    all_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        batch_number = 0\n",
    "        for data in dataloader:\n",
    "            input1, input2, target_similarity = data\n",
    "            optimizer.zero_grad()\n",
    "            output_similarity = model(input1, input2)\n",
    "            # Convertir target_similarity al mismo tipo de dato que output_similarity\n",
    "            target_similarity = target_similarity.to(output_similarity.dtype)\n",
    "            loss = criterion(output_similarity, target_similarity)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch_num % 100 == 0:\n",
    "                all_losses.append(loss.item())\n",
    "            if batch_num % 200 == 0:\n",
    "                print(f\"Batch number:: {batch_num}\")\n",
    "            batch_number = batch_number + 1\n",
    "\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "        \n",
    "    print(\"::: ...Fin del entrenamiento :::\")\n",
    "    return all_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear un modelo llamado *modelo* (por quora question pairs). Y vamos a ir entrenando por separado cada epoch. Después de entrenar un epoc vamos a ir guardando el modelo en la dirección especificada. Esto para no perder el progreso del entrenamiento si se  acaba la memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo\n",
    "modelo = SiameseNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: Iniciando entrenamiento... :::\n",
      "Epoch 0, Loss: 0.2649436295032501\n",
      "Epoch 1, Loss: 0.21263937652111053\n",
      "Epoch 2, Loss: 0.2590460181236267\n",
      "Epoch 3, Loss: 0.21791104972362518\n",
      "Epoch 4, Loss: 0.2085525244474411\n",
      "Epoch 5, Loss: 0.21562479436397552\n",
      "Epoch 6, Loss: 0.2957985997200012\n",
      "Epoch 7, Loss: 0.21295708417892456\n",
      "Epoch 8, Loss: 0.18642425537109375\n",
      "Epoch 9, Loss: 0.22216437757015228\n",
      "::: ...Fin del entrenamiento :::\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos un epoch\n",
    "losses = train(dataloader_train, modelo, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos\n",
    "torch.save(modelo.state_dict(), \"modelo_qqp.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  0\n",
      "batch:  10\n",
      "batch:  20\n",
      "batch:  30\n",
      "batch:  40\n",
      "batch:  50\n",
      "batch:  0\n",
      "batch:  10\n",
      "batch:  20\n",
      "batch:  30\n",
      "batch:  40\n",
      "batch:  50\n",
      "size q1: torch.Size([29698, 15, 300])\n",
      "size q2: torch.Size([29698, 15, 300])\n",
      "size targets: torch.Size([29698])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 534564000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m dataloader_test \u001b[38;5;241m=\u001b[39m DataLoader(dataset_test, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(X_test), shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m question1_batch, question2_batch, isDuplicate_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataloader_test))\n\u001b[1;32m----> 7\u001b[0m predicted_similarity \u001b[38;5;241m=\u001b[39m \u001b[43mmodelo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion1_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion2_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[54], line 26\u001b[0m, in \u001b[0;36mSiameseNetwork.forward\u001b[1;34m(self, input1, input2)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Pasamos la pregunta 2:\u001b[39;00m\n\u001b[0;32m     25\u001b[0m input2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositionalEncoder(input2)\n\u001b[1;32m---> 26\u001b[0m output2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m output2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavg_pool(output2)\n\u001b[0;32m     28\u001b[0m output2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(output2, start_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\transformer.py:574\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    573\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, src_mask, src_key_padding_mask))\n\u001b[1;32m--> 574\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ff_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\transformer.py:590\u001b[0m, in \u001b[0;36mTransformerEncoderLayer._ff_block\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    589\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1(x))))\n\u001b[1;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\modules\\dropout.py:59\u001b[0m, in \u001b[0;36mDropout.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\nn\\functional.py:1252\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(p))\n\u001b[1;32m-> 1252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 534564000 bytes."
     ]
    }
   ],
   "source": [
    "# Con el conjunto de prueba\n",
    "X, targets = prepare_sample_df_for_dataloader(X_test.question1_vectors, X_test.question2_vectors, Y_test)\n",
    "dataset_test = QuestionsDataset(X['question1'], X['question2'], targets)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=16, shuffle=True)\n",
    "question1_batch, question2_batch, isDuplicate_batch = next(iter(dataloader_test))\n",
    "\n",
    "predicted_similarity = modelo(question1_batch, question2_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predicted_similarity = predicted_similarity.detach()\n",
    "predicted_similarity = torch.where(predicted_similarity > 0.7, 1, 0)\n",
    "accuracy_score(isDuplicate_batch, predicted_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17048e721a0>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Define the MSE loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "all_losses = []\n",
    "losses_per_epoch = []\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: min(1.0, (epoch + 1) / (0.1 * num_epochs)))\n",
    "\n",
    "print(\"Iniciando el entrenamiento...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss = 0\n",
    "    print(\"~ Epoch:\", epoch+1)\n",
    "    batch_num = 0\n",
    "    for data in train_dataloader:\n",
    "        \n",
    "        input1, input2, target_similarity = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_similarity = model(input1, input2)\n",
    "        \n",
    "        # Convertir target_similarity al mismo tipo de dato que output_similarity\n",
    "        target_similarity = target_similarity.to(output_similarity.dtype)\n",
    "\n",
    "        loss = criterion(output_similarity, target_similarity)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        if batch_num % 300 == 0:\n",
    "            print(f\"Batch number:: {batch_num}\")\n",
    "            all_losses.append(loss.item())\n",
    "        batch_num = batch_num + 1\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}, Learning Rate: {scheduler.get_last_lr()[0]}\")\n",
    "    losses_per_epoch.append(loss.item())\n",
    "print(\"¡Fin del entrenamiento!\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
