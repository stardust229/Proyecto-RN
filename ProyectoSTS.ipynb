{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto STS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import LambdaLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\usuario.DESKTOP-\n",
      "[nltk_data]     GDR7TES\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x146de2ad7d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(777) # seed para reproductibilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lectura de datos.** Dado que en este caso nuestros datos vienen en texto, necesitaremos realizar un \n",
    "proceso diferente para obtener los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df= pd.read_csv('train.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\usuario.DESKTOP-GDR7TES\\AppData\\Local\\Temp\\ipykernel_8224\\728090549.py:2: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test_df= pd.read_csv('test.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test_id                                          question1  \\\n",
       "0       0  How does the Surface Pro himself 4 compare wit...   \n",
       "1       1  Should I have a hair transplant at age 24? How...   \n",
       "2       2  What but is the best way to send money from Ch...   \n",
       "3       3                        Which food not emulsifiers?   \n",
       "4       4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# El csv con datos para prueba no tiene columna target, así que no lo vamos a usar.\n",
    "test_df= pd.read_csv('test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Separación de las preguntas en tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función es parte del preprocesamiento. Vamos a convertir cada oración en una lista de palabras, y vamos a homogenizar contracciones comunes de palabras en ingles (ya que las preguntas están en inglés)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "\n",
    "def text_to_word_list(text):\n",
    "    ''' Pre process and convert texts to a list of words '''\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    text = text.split()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que hacer lo siguiente: Para cada dataset, agregar las columnas `question1_vec` y `question2_vec`. Estas columnas contienen la respresentación de las preguntas como listas de embeddings, donde cada embedding (vector) corresponde a una de las palabras (tokens) de la pregunta.\n",
    "\n",
    "Para hacer esto, primero pasaremos cada pregunta por la función `text_to_word_list`, obteniendo la lista de tokens que le corresponden. En esta función se homogenizan algunas contracciones comunes.\n",
    "\n",
    "El resultado de pasar nuestar pregunta por `text_to_word_list` lo agregaremos al dataframe como una columna `question1_tokens` o `question2_tokens`.\n",
    "\n",
    "Luego, por cada lista de tokens, usaremos un modelo pre-entrenado de Word2Vec para asignarle un vector a cada palabra de la lista. Estas listas de vectores las guardaremos en las columnas `question1_vec` y `question2_vec`.\n",
    "\n",
    "Estas listas de vectores serán la entrada de nuestro modelo más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training dataset:\n",
    "train_question1_tokens = [text_to_word_list(q) for q in train_df['question1']]\n",
    "train_df['question1_tokens'] = train_question1_tokens\n",
    "\n",
    "train_question2_tokens = [text_to_word_list(q) for q in train_df['question2']]\n",
    "train_df['question2_tokens'] = train_question2_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora nuestro dataframe de entrenamiento tiene las columas extra:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question1_tokens</th>\n",
       "      <th>question2</th>\n",
       "      <th>question2_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>[what, is, the, story, of, kohinoor, koh, -, i...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>[what, would, happen, if, the, indian, governm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>[how, can, i, increase, the, speed, of, my, in...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>[how, can, internet, speed, be, increased, by,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>[why, am, i, mentally, very, lonely, how, can,...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>[find, the, remainder, when, math, 23, ^, 24, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>[which, one, dissolve, in, water, quikly, suga...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>[which, fish, would, survive, in, salt, water]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                    question1_tokens  \\\n",
       "0  [what, is, the, step, by, step, guide, to, inv...   \n",
       "1  [what, is, the, story, of, kohinoor, koh, -, i...   \n",
       "2  [how, can, i, increase, the, speed, of, my, in...   \n",
       "3  [why, am, i, mentally, very, lonely, how, can,...   \n",
       "4  [which, one, dissolve, in, water, quikly, suga...   \n",
       "\n",
       "                                           question2  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What would happen if the Indian government sto...   \n",
       "2  How can Internet speed be increased by hacking...   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...   \n",
       "4            Which fish would survive in salt water?   \n",
       "\n",
       "                                    question2_tokens  \n",
       "0  [what, is, the, step, by, step, guide, to, inv...  \n",
       "1  [what, would, happen, if, the, indian, governm...  \n",
       "2  [how, can, internet, speed, be, increased, by,...  \n",
       "3  [find, the, remainder, when, math, 23, ^, 24, ...  \n",
       "4     [which, fish, would, survive, in, salt, water]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['question1', 'question1_tokens', 'question2', 'question2_tokens']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Agregar embeddings de Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tranformamos las listas de tokens a arreglos de numpy con su representación en vectores. Agregamos esas columnas al dataframe.\n",
    "\n",
    "Usaremos un modelo pre-entrenado de Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Cargamos el modelo pre-entrenado de word2vec\n",
    "model_file = \"w2v_model/google_news_word2vec.model\"\n",
    "word2vec = KeyedVectors.load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_vector(token):\n",
    "    try:\n",
    "        return word2vec[token]\n",
    "    except KeyError:\n",
    "        return None\n",
    "\n",
    "def tokens_to_vectors(token_list):\n",
    "    # si la palabra no existe en el vocabulario de word2vec, sólo la saltamos\n",
    "    vector_list = [vector for token in token_list if (vector := get_vector(token)) is not None]\n",
    "    if len(vector_list) > 0:\n",
    "        return vector_list\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training dataset:\n",
    "train_question1_vectors = [tokens_to_vectors(tk) for tk in train_df['question1_tokens']]\n",
    "train_df['question1_vectors'] = train_question1_vectors\n",
    "\n",
    "train_question2_vectors = [tokens_to_vectors(tk) for tk in train_df['question2_tokens']]\n",
    "train_df['question2_vectors'] = train_question2_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before dropping rows with missing values: 404290\n",
      "After dropping rows with missing values: 404253\n"
     ]
    }
   ],
   "source": [
    "# Ahora eliminaremos las filas con algún valor None\n",
    "print('Before dropping rows with missing values:', len(train_df['question1_vectors']))\n",
    "train_df.dropna(inplace=True)\n",
    "print('After dropping rows with missing values:', len(train_df['question1_vectors']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question1_vectors</th>\n",
       "      <th>question2</th>\n",
       "      <th>question2_vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>[[0.13964844, -0.006164551, 0.21484375, 0.0727...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>[[0.13964844, -0.006164551, 0.21484375, 0.0727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>[[0.13964844, -0.006164551, 0.21484375, 0.0727...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>[[0.13964844, -0.006164551, 0.21484375, 0.0727...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>[[0.26953125, 0.0859375, 0.09423828, 0.0410156...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>[[0.26953125, 0.0859375, 0.09423828, 0.0410156...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>[[0.15136719, 0.012451172, 0.21777344, 0.03039...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>[[-0.006958008, -0.043701172, -0.16796875, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>[[-0.06933594, 0.044677734, 0.091796875, 0.052...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>[[-0.06933594, 0.044677734, 0.091796875, 0.052...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question1  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2  How can I increase the speed of my internet co...   \n",
       "3  Why am I mentally very lonely? How can I solve...   \n",
       "4  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                   question1_vectors  \\\n",
       "0  [[0.13964844, -0.006164551, 0.21484375, 0.0727...   \n",
       "1  [[0.13964844, -0.006164551, 0.21484375, 0.0727...   \n",
       "2  [[0.26953125, 0.0859375, 0.09423828, 0.0410156...   \n",
       "3  [[0.15136719, 0.012451172, 0.21777344, 0.03039...   \n",
       "4  [[-0.06933594, 0.044677734, 0.091796875, 0.052...   \n",
       "\n",
       "                                           question2  \\\n",
       "0  What is the step by step guide to invest in sh...   \n",
       "1  What would happen if the Indian government sto...   \n",
       "2  How can Internet speed be increased by hacking...   \n",
       "3  Find the remainder when [math]23^{24}[/math] i...   \n",
       "4            Which fish would survive in salt water?   \n",
       "\n",
       "                                   question2_vectors  \n",
       "0  [[0.13964844, -0.006164551, 0.21484375, 0.0727...  \n",
       "1  [[0.13964844, -0.006164551, 0.21484375, 0.0727...  \n",
       "2  [[0.26953125, 0.0859375, 0.09423828, 0.0410156...  \n",
       "3  [[-0.006958008, -0.043701172, -0.16796875, 0.1...  \n",
       "4  [[-0.06933594, 0.044677734, 0.091796875, 0.052...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['question1', 'question1_vectors', 'question2', 'question2_vectors']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a guardar por aquí la longitud máxima de la lista de tokens para ambas preguntas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length_question1 = train_df['question1_tokens'].apply(lambda x: len(x)).max()\n",
    "max_length_question2 = train_df['question2_tokens'].apply(lambda x: len(x)).max()\n",
    "max_length_question = max_length_question1 if max_length_question1 >= max_length_question2 else max_length_question2\n",
    "max_length_question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Crear conjuntos de entrenamiento y prueba, y prepararlos para el dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*train_df* tiene demasiados ejemplares para la capacidad de cómputo con la que contamos, así que vamos a dividirlo en varios conjuntos de entrenamiento, y vamos a ir entrenando el modelo con cada uno por separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para que sea más fácil, sólo vamos a usar las primeras 400,000 filas.\n",
    "num_samples = 400000\n",
    "train_df = train_df.head(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_size = num_samples // 10\n",
    "\n",
    "# Dividimos el dataframe\n",
    "samples_collection = [train_df[i:i+chunk_size] for i in range(0, num_samples, chunk_size)]\n",
    "\n",
    "len(samples_collection[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define una función para transformar las columnas de los conjuntos a listas de tensores, para que puedan ser usados en el dataloader.\n",
    "\n",
    "También se define una función para agregarle padding a las secuencias, para que todas sean del mismo tamaño (los espacios extras se llenan con 0s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedded_vectors_to_tensors(question1_vectors, question2_vectors):\n",
    "    # Cambiamos los conjuntos a un diccionario y los transformamos en\n",
    "    # arreglos de numpy\n",
    "    X = {\n",
    "        'question1': [np.array(vecs) for vecs in question1_vectors],\n",
    "        'question2': [np.array(vecs) for vecs in question2_vectors]\n",
    "    }\n",
    "    # Ahora, transformamos las listas de las columnas de vectores en listas de tensores.\n",
    "    X = {\n",
    "        'question1': [torch.tensor(np_vecs) for np_vecs in X['question1']],\n",
    "        'question2': [torch.tensor(np_vecs) for np_vecs in X['question2']]\n",
    "    }\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Recibe una lista de (# de ejemplares) tensores de tamaño [max_sequence_length, word_vectors_length].\n",
    "Regresa un tensor de tamaño [# de ejemplares, max_sequence_length, word_vectors_length], con todos\n",
    "sus tensores de tamaño max_sequence_length con 0s en los espacios donde originalmente no había nada (padding).\n",
    "(Checa torch.nn.utils.rnn.pad_sequence)\n",
    "\"\"\"\n",
    "def tensorize_and_pad_sequences(sequences, max_sequence_length, word_vectors_length):\n",
    "    batch_size = 500  # Adjust the batch size as per your memory constraints\n",
    "    num_batches = (len(sequences) + batch_size - 1) // batch_size\n",
    "\n",
    "    dummy_tensor = torch.ones(max_sequence_length, word_vectors_length)\n",
    "\n",
    "    padded_sequences = []\n",
    "    for i in range(num_batches):\n",
    "        if i % 100 == 0:\n",
    "            print('batch: ',i)\n",
    "        batch = sequences[i * batch_size : (i + 1) * batch_size]\n",
    "        num_rows = len(batch)\n",
    "        batch.append(dummy_tensor)\n",
    "        padded_batch = torch.nn.utils.rnn.pad_sequence(batch, batch_first=True)\n",
    "        padded_batch = torch.index_select(padded_batch, 0, torch.arange(num_rows))\n",
    "        padded_sequences.append(padded_batch)\n",
    "\n",
    "    return torch.cat(padded_sequences, dim=0)  # Concatenate the batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, se crea una función que recibe un dataframe de *samples_collection*, y regresa un diccionario X con un tensor para cada pregunta (question1 y question2) y uno para targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors_length = 300\n",
    "\n",
    "def prepare_sample_df_for_dataloader(sample_df):\n",
    "    question1_vectors = sample_df['question1_vectors']\n",
    "    question2_vectors = sample_df['question2_vectors']\n",
    "    targets = sample_df['is_duplicate']\n",
    "    \n",
    "    X = embedded_vectors_to_tensors(question1_vectors, question2_vectors)\n",
    "    X['question1'] = tensorize_and_pad_sequences(X['question1'], max_length_question, word_vectors_length)\n",
    "    X['question2'] = tensorize_and_pad_sequences(X['question2'], max_length_question, word_vectors_length)\n",
    "    \n",
    "    targets = targets.values.tolist()\n",
    "    targets = torch.tensor(targets)\n",
    "    \n",
    "    print('size q1:', X['question1'].size()) # X.question1 tiene tamaño (NUM_EJEMPLARES, MAX_SENT_LEN, EMBEDDING_DIM).\n",
    "    print('size q2:', X['question2'].size())\n",
    "    print('size targets:', targets.size())\n",
    "    \n",
    "    return X, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Creación del DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un DataSet y DataLoader para el conjunto de entrenamiento y de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class QuestionsDataset(Dataset):\n",
    "    def __init__(self, question1, question2, targets):\n",
    "        self.question1 = question1\n",
    "        self.question2 = question2\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        question1 = self.question1[index]\n",
    "        question2 = self.question2[index]\n",
    "        isDuplicate = self.targets[index]\n",
    "\n",
    "        return question1, question2, isDuplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:  0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 11712000000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# El resultado de prepare_sample_df_for_dataloader lo podemos convertir a un QuestionsDataset para ingresarlo en el dataloader\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Ejemplo:\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m X, targets \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_sample_df_for_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples_collection\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m dataset_ejemplo \u001b[38;5;241m=\u001b[39m QuestionsDataset(X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion1\u001b[39m\u001b[38;5;124m'\u001b[39m], X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion2\u001b[39m\u001b[38;5;124m'\u001b[39m], targets)\n\u001b[0;32m      5\u001b[0m dataloader_ejemplo \u001b[38;5;241m=\u001b[39m DataLoader(dataset_ejemplo, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[23], line 9\u001b[0m, in \u001b[0;36mprepare_sample_df_for_dataloader\u001b[1;34m(sample_df)\u001b[0m\n\u001b[0;32m      6\u001b[0m targets \u001b[38;5;241m=\u001b[39m sample_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_duplicate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m embedded_vectors_to_tensors(question1_vectors, question2_vectors)\n\u001b[1;32m----> 9\u001b[0m X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtensorize_and_pad_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length_question\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_vectors_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m tensorize_and_pad_sequences(X[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion2\u001b[39m\u001b[38;5;124m'\u001b[39m], max_length_question, word_vectors_length)\n\u001b[0;32m     12\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()\n",
      "Cell \u001b[1;32mIn[22], line 24\u001b[0m, in \u001b[0;36mtensorize_and_pad_sequences\u001b[1;34m(sequences, max_sequence_length, word_vectors_length)\u001b[0m\n\u001b[0;32m     21\u001b[0m     padded_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mindex_select(padded_batch, \u001b[38;5;241m0\u001b[39m, torch\u001b[38;5;241m.\u001b[39marange(num_rows))\n\u001b[0;32m     22\u001b[0m     padded_sequences\u001b[38;5;241m.\u001b[39mappend(padded_batch)\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpadded_sequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 11712000000 bytes."
     ]
    }
   ],
   "source": [
    "# El resultado de prepare_sample_df_for_dataloader lo podemos convertir a un QuestionsDataset para ingresarlo en el dataloader\n",
    "# Ejemplo:\n",
    "X, targets = prepare_sample_df_for_dataloader(samples_collection[0])\n",
    "dataset_ejemplo = QuestionsDataset(X['question1'], X['question2'], targets)\n",
    "dataloader_ejemplo = DataLoader(dataset_ejemplo, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# vemos que el tamaño sea correcto\n",
    "question1_batch, question2_batch, isDuplicate_batch = next(iter(dataloader_ejemplo))\n",
    "question1_batch.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Definición del modelo\n",
    "Una vez que se tienen las entradas, el modelo necesita 3 cosas: el codificador posicional, el encoder del transformador, y una función de similitud entre dos vectores (las salidas del encoder del transformador). Estas tres cosas las vamos a integrar en una red neuronal siamesa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Codificación posicional\n",
    "Se les aplica una codificación posicional a las secuencias de embeddings, para tomar en cuenta el orden de las secuencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "En el paper original por Vaswani et al., la matriz para codificar la posición se obtenía con las siguientes fórmulas:\n",
    "$$\n",
    "PE(\\text{position}, 2i) = \\sin\\bigg( \\frac{ \\text{position} }{10000^\\frac{2i}{d}} \\bigg)\n",
    "$$\n",
    "\n",
    "$$\n",
    "PE(\\text{position}, 2i+1) = \\cos\\bigg( \\frac{ \\text{position} }{10000^\\frac{2i}{d}} \\bigg)\n",
    "$$\n",
    "\n",
    "donde *d* es la dimensión de los vectores de los tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para hacer la codificación posicional se crea una clase PositionalEncoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Create the positional encoding matrix\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        position = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Add the positional encoding to the input\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Antes de realizar la codificación posicional, intercambiamos la primera y segunda dimensión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "positionalEncoder = PositionalEncoding(word_vectors_length, max_seq_len = max_length_question)\n",
    "question1_batch = positionalEncoder(question1_batch)\n",
    "print(question1_batch.shape)              # (BATCH_SIZE, SEQ_LEN, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### El encoder del transformador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = word_vectors_length\n",
    "HIDDEN_SIZE = 16\n",
    "NUM_HEADS = 5\n",
    "DROPOUT = .3\n",
    "\n",
    "enc_layer = nn.TransformerEncoderLayer(EMBEDDING_DIM, NUM_HEADS, HIDDEN_SIZE, DROPOUT, batch_first=True)\n",
    "encoder_result = enc_layer(question1_batch)\n",
    "print(encoder_result.shape)                      # (SEQ_LEN, BATCH_SIZE, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Pooling\n",
    "En el paper de SBERT usan mean pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "one_encoder_result = encoder_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poolingLayer = nn.AvgPool2d(kernel_size=(1, word_vectors_length), stride=(1, word_vectors_length))\n",
    "output = poolingLayer(one_encoder_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### La función de similitud\n",
    "En el paper de SBERT usan cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = torch.flatten(output, start_dim=1)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cos_similarity = nn.CosineSimilarity(dim=1)\n",
    "cos_similarity(output, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Construcción de la red siamesa\n",
    "La red va a tener un encoder de transformador en cada lado, y los vectores resultantes se van a comparar con cosine_similarity ???\n",
    "\n",
    "// Mostrar una imagen de la arquitectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        # Positional Encodding Layer\n",
    "        self.positionalEncoder = PositionalEncoding(word_vectors_length, max_seq_len = max_length_question)\n",
    "\n",
    "        # Shared Transformer Encoder Layer\n",
    "        self.transformer_encoder = nn.TransformerEncoderLayer(EMBEDDING_DIM, NUM_HEADS, HIDDEN_SIZE, DROPOUT, batch_first=True)\n",
    "\n",
    "        # Pooling Layer\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=(1, word_vectors_length), stride=(1, word_vectors_length))\n",
    "\n",
    "        # Cosine Similarity\n",
    "        self.cos_similarity = nn.CosineSimilarity(dim=1)\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        # Pasamos la pregunta 1:\n",
    "        input1 = self.positionalEncoder(input1)\n",
    "        output1 = self.transformer_encoder(input1)\n",
    "        output1 = self.avg_pool(output1)\n",
    "        output1 = torch.flatten(output1, start_dim=1)\n",
    "        \n",
    "        # Pasamos la pregunta 2:\n",
    "        input2 = self.positionalEncoder(input2)\n",
    "        output2 = self.transformer_encoder(input2)\n",
    "        output2 = self.avg_pool(output2)\n",
    "        output2 = torch.flatten(output2, start_dim=1)\n",
    "\n",
    "        # Compute Cosine Similarity\n",
    "        similarity = self.cos_similarity(output1, output2)\n",
    "\n",
    "        return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento\n",
    "En el paper de SBERT usan  batch-size of 16, Adam optimizer with\n",
    "learning rate 2e−5, and a linear learning rate\n",
    "warm-up over 10% of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the MSE loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def train_one_epoch(dataloader, model):\n",
    "    print(\"::: Entrenamiento de un epoch :::\")\n",
    "    \n",
    "    all_losses = []\n",
    "    batch_num = 0\n",
    "    for data in train_dataloader:\n",
    "        input1, input2, target_similarity = data\n",
    "        optimizer.zero_grad()\n",
    "        output_similarity = model(input1, input2)\n",
    "        # Convertir target_similarity al mismo tipo de dato que output_similarity\n",
    "        target_similarity = target_similarity.to(output_similarity.dtype)\n",
    "        loss = criterion(output_similarity, target_similarity)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_num % 300 == 0:\n",
    "            print(f\"Batch {batch_num + 1}, Loss: {loss.item()}\")\n",
    "            all_losses.append(loss.item())\n",
    "        batch_num = batch_num + 1\n",
    "\n",
    "    print(\"::: fin :::\")\n",
    "    return all_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear un modelo llamado *modelo_qqp* (por quora question pairs). Y vamos a ir entrenando por separado con cada conjunto de *samples_collection*. Después de entrenar con cada elemento de la colección vamos a ir guardando el modelo en la dirección especificada. Esto para no perder el progreso del entrenamiento si se  acaba la memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo\n",
    "modelo_qqp = SiameseNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entonces, para entrenar uno de los conjuntos de ejemplares de samples_collection:\n",
    "X, targets = prepare_sample_df_for_dataloader(samples_collection[0])\n",
    "dataset = QuestionsDataset(X['question1'], X['question2'], targets)\n",
    "dataloader = DataLoader(dataset_ejemplo, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "losses = train_one_epoch(dataloader, modelo_qqp)\n",
    "\n",
    "torch.save(modelo_qqp.state_dict(), \"modelo_qqp.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Define the MSE loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "all_losses = []\n",
    "losses_per_epoch = []\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: min(1.0, (epoch + 1) / (0.1 * num_epochs)))\n",
    "\n",
    "print(\"Iniciando el entrenamiento...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss = 0\n",
    "    print(\"~ Epoch:\", epoch+1)\n",
    "    batch_num = 0\n",
    "    for data in train_dataloader:\n",
    "        \n",
    "        input1, input2, target_similarity = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_similarity = model(input1, input2)\n",
    "        \n",
    "        # Convertir target_similarity al mismo tipo de dato que output_similarity\n",
    "        target_similarity = target_similarity.to(output_similarity.dtype)\n",
    "\n",
    "        loss = criterion(output_similarity, target_similarity)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "        \n",
    "        if batch_num % 300 == 0:\n",
    "            print(f\"Batch number:: {batch_num}\")\n",
    "            all_losses.append(loss.item())\n",
    "        batch_num = batch_num + 1\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}, Learning Rate: {scheduler.get_last_lr()[0]}\")\n",
    "    losses_per_epoch.append(loss.item())\n",
    "print(\"¡Fin del entrenamiento!\")\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
